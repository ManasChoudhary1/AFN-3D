{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "306eccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import sys\n",
    "import os\n",
    "from encoders.base import EncoderBase\n",
    "from monai.networks.nets import SegResNet\n",
    "from typing import Dict, List, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c769a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from building_blocks import UAFS\n",
    "from building_blocks import MAFS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b57f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonaiSegResNetEncoder(EncoderBase):\n",
    "    \"\"\"\n",
    "    Wraps MONAI's SegResNet to function as a pure encoder.\n",
    "    \n",
    "    Why SegResNet?\n",
    "    - Uses GroupNorm by default (better for small batch sizes in 3D).\n",
    "    - Highly optimized for GPU memory.\n",
    "    - Native .encode() method returns hierarchical features.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int = 1, \n",
    "        feature_channels: List[int] = [16, 32, 64, 128], \n",
    "        spatial_dims: int = 3\n",
    "    ):\n",
    "        # SegResNet expects an `init_filters` arg (the first stage width)\n",
    "        # and `dropout_prob` etc.\n",
    "        # We assume feature_channels follows a doubling pattern like [16, 32, 64, 128]\n",
    "        \n",
    "        super().__init__(in_channels, feature_channels)\n",
    "        \n",
    "        self.net = SegResNet(\n",
    "            spatial_dims=spatial_dims,\n",
    "            init_filters=feature_channels[0], # e.g. 16\n",
    "            in_channels=in_channels,\n",
    "            out_channels=1, # Dummy value, we won't use the decoder\n",
    "            dropout_prob=0.2,\n",
    "            # blocks_down defines how many ResNet blocks per stage. \n",
    "            # [1, 2, 2, 4] is a common default configuration.\n",
    "            blocks_down=(1, 2, 2, 4), \n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        SegResNet.encode(x) returns:\n",
    "          - x_final (Tensor): The bottleneck feature (lowest resolution)\n",
    "          - down_x (List[Tensor]): A list of intermediate features (high to low res)\n",
    "                                   BUT usually in reverse order of generation? \n",
    "                                   Let's verify the standard behavior.\n",
    "        \"\"\"\n",
    "        # MONAI SegResNet encode returns:\n",
    "        # x (bottleneck), layers (list of skip connections)\n",
    "        bottleneck, skips = self.net.encode(x)\n",
    "        \n",
    "        # skips contains features from [Resolution 1, Resolution 1/2, Resolution 1/4 ...]\n",
    "        # bottleneck is Resolution 1/8 (if 4 stages)\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # 1. Add the high-res stages from the skip connections\n",
    "        # Note: skips[0] is usually the input convolution output (Resolution 1)\n",
    "        for i, skip in enumerate(skips):\n",
    "            features[f\"stage{i+1}\"] = skip\n",
    "            \n",
    "        # 2. Add the bottleneck as the final stage\n",
    "        final_stage_idx = len(skips) + 1\n",
    "        features[f\"stage{final_stage_idx}\"] = bottleneck\n",
    "        \n",
    "        return features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438561b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AFN3D(nn.Module): ## I assume symetrical input \n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = MonaiSegResNetEncoder(in_channels=1,feature_channels=[16,32,64,128],spatial_dims = 3)\n",
    "        self.uafs1 = UAFS(128,64)\n",
    "        self.uafs2 = UAFS(64, 32)\n",
    "        self.uafs3 = UAFS(32,16)\n",
    "        self.mafs = MAFS(16)\n",
    "\n",
    "    def forward(self,x:torch.Tensor):\n",
    "\n",
    "        features = self.encoder(x) ## stage1-16 stage2-32 stage3-64 \n",
    "        x_s = x_t = features[\"stage4\"]\n",
    "        x_s, x_t = self.uafs1(x_s,x_t,features[\"stage3\"])\n",
    "        x_s, x_t = self.uafs2(x_s,x_t,features[\"stage2\"])\n",
    "        x_s, x_t = self.uafs3(x_s,x_t,features[\"stage1\"])\n",
    "        pred,affs = self.mafs(x_s,x_t)\n",
    "        print(pred.shape,affs.shape)\n",
    "        return pred, affs\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2566d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AFN3D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cee90e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand([3,1,64,64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0231e90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 64, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a3b9a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 8, 8, 8])\n",
      "torch.Size([3, 64, 16, 16, 16])\n",
      "torch.Size([3, 32, 32, 32, 32])\n",
      "torch.Size([3, 1, 64, 64, 64]) torch.Size([3, 78, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "output = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f37c481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cac10c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
